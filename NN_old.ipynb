{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc3f599",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48003d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446235ff",
   "metadata": {},
   "source": [
    "todo: initialise constants from the dataset (drop name column)\n",
    "todo: redefine feed forward generally\n",
    "todo: do todo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1bc6f",
   "metadata": {},
   "source": [
    "Intialise network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba24926",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3  # number of layers(excluding input layer)\n",
    "n = 2  # number of features\n",
    "m = 1  # number of output nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e358a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(input_size=n, hidden_size=n+1, output_size=m, num_hidden_layers=L-1):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    # Input to first hidden layer\n",
    "    weights.append(np.random.randn(hidden_size, input_size) * 0.01)\n",
    "    biases.append(np.random.randn(hidden_size, 1) * 0.01)\n",
    "    \n",
    "    # Hidden layers\n",
    "    for _ in range(num_hidden_layers - 1):\n",
    "        weights.append(np.random.randn(hidden_size, hidden_size) * 0.01)\n",
    "        biases.append(np.random.randn(hidden_size, 1) * 0.01)\n",
    "    \n",
    "    # Last hidden to output layer\n",
    "    weights.append(np.random.randn(output_size, hidden_size) * 0.01)\n",
    "    biases.append(np.random.randn(output_size, 1) * 0.01)\n",
    "    \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803fd336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.00335866],\n",
      "       [ 0.00910995],\n",
      "       [-0.0087456 ]]), array([[ 0.01440529],\n",
      "       [-0.00037041],\n",
      "       [-0.01520825]]), array([[-0.00275494]])]\n",
      "[array([[ 0.01052895,  0.0016054 ],\n",
      "       [ 0.00325803, -0.00444898],\n",
      "       [ 0.00986181,  0.00699666]]), array([[-0.0056421 ,  0.02261084,  0.00528095],\n",
      "       [ 0.01258079,  0.01143449, -0.00271798],\n",
      "       [-0.01236303,  0.0198675 ,  0.00505116]]), array([[ 0.00637807, -0.00090319, -0.00943798]])]\n"
     ]
    }
   ],
   "source": [
    "print(init_network()[1])\n",
    "print(init_network()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d67cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "n = [2, 3, 3, 1]\n",
    "# Generates matrices rowsxcols with random floats\n",
    "W1 = np.random.randn(n[1], n[0])\n",
    "W2 = np.random.randn(n[2], n[1])\n",
    "W3 = np.random.randn(n[3], n[2])\n",
    "b1 = np.random.randn(n[1], 1)\n",
    "b2 = np.random.randn(n[2], 1)\n",
    "b3 = np.random.randn(n[3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a42ead4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49164326  1.83399003]\n",
      " [ 1.12384124 -0.11126868]\n",
      " [ 2.40686708  0.70634631]]\n"
     ]
    }
   ],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c54697",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ce2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "  X = np.array([\n",
    "      [150, 70],\n",
    "      [254, 73],\n",
    "      [312, 68],\n",
    "      [120, 60],\n",
    "      [154, 61],\n",
    "      [212, 65],\n",
    "      [216, 67],\n",
    "      [145, 67],\n",
    "      [184, 64],\n",
    "      [130, 69]\n",
    "  ])\n",
    "  y = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "  m = 10\n",
    "  # Transpose the input matrix\n",
    "  A0 = X.T\n",
    "  Y = y.reshape(n[L], m)\n",
    "\n",
    "  return A0, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912562bf",
   "metadata": {},
   "source": [
    "Training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75a2b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([\n",
    "    0,\n",
    "    1, \n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "    0\n",
    "])\n",
    "m = 10\n",
    "# we need to reshape to a n^[3] x m matrix\n",
    "Y = y.reshape(n[3], m)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ed4b5",
   "metadata": {},
   "source": [
    "Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d161c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(arr):\n",
    "    return 1 / (1+np.exp(-1*arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c4b8e",
   "metadata": {},
   "source": [
    "Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd8be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(A0, layers=L):\n",
    "  # layer 1 calculations\n",
    "  Z1 = W1 @ A0 + b1\n",
    "  A1 = sigmoid(Z1)\n",
    "\n",
    "  # layer 2 calculations\n",
    "  Z2 = W2 @ A1 + b2\n",
    "  A2 = sigmoid(Z2)\n",
    "\n",
    "  # layer 3 calculations\n",
    "  Z3 = W3 @ A2 + b3\n",
    "  A3 = sigmoid(Z3)\n",
    "\n",
    "  cache = {\n",
    "      \"A0\": A0,\n",
    "      \"A1\": A1,\n",
    "      \"A2\": A2\n",
    "  }\n",
    "\n",
    "  return A3, cache\n",
    "\n",
    "A0, Y = prepare_data()\n",
    "y_hat = feed_forward(A0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb48ba",
   "metadata": {},
   "source": [
    "Use loss as cost function: $L\\left(\\hat{y}_i y_i\\right)=-\\left(y_i \\ln \\hat{y}_i+\\left(1-y_i\\right) \\ln \\left(1-\\hat{y}_i\\right)\\right)$\n",
    "\n",
    "\n",
    "Hence cost given by: $C=\\frac{1}{m} \\sum_{i=1}^m L\\left(\\hat{y}_i, y_i\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f5db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_hat, y):\n",
    "  \"\"\"\n",
    "  y_hat should be a n^L x m matrix\n",
    "  y should be a n^L x m matrix\n",
    "  \"\"\"\n",
    "\n",
    "  # Clip predictions to avoid log(0)\n",
    "  y_hat = np.clip(y_hat, 1e-15, 1 - 1e-15)\n",
    "\n",
    "  # 1. losses is a n^L x m\n",
    "  losses = - ( (y * np.log(y_hat)) + (1 - y)*np.log(1 - y_hat) )\n",
    "\n",
    "  return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb06e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 1 0 1 0]]\n",
      "[[0.07064369 0.07064369 0.07064369 0.07064369 0.07064369 0.07064369\n",
      "  0.07064369 0.07064369 0.07064369 0.07064369]]\n",
      "1.3616847531073537\n"
     ]
    }
   ],
   "source": [
    "print(Y)\n",
    "print(y_hat)\n",
    "print(cost(y_hat, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0125e8c",
   "metadata": {},
   "source": [
    "Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8843ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_layer_3(y_hat, Y, m, A2, W3):\n",
    "  A3 = y_hat\n",
    "  \n",
    "  # step 1. calculate dC/dZ3 using shorthand we derived earlier\n",
    "  dC_dZ3 = (1/m) * (A3 - Y)\n",
    "  assert dC_dZ3.shape == (n[3], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW3 = dC/dZ3 * dZ3/dW3 \n",
    "  #   we matrix multiply dC/dZ3 with (dZ3/dW3)^T\n",
    "  dZ3_dW3 = A2\n",
    "  assert dZ3_dW3.shape == (n[2], m)\n",
    "\n",
    "  dC_dW3 = dC_dZ3 @ dZ3_dW3.T\n",
    "  assert dC_dW3.shape == (n[3], n[2])\n",
    "\n",
    "  # step 3. calculate dC/db3 = np.sum(dC/dZ3, axis=1, keepdims=True)\n",
    "  dC_db3 = np.sum(dC_dZ3, axis=1, keepdims=True)\n",
    "  assert dC_db3.shape == (n[3], 1)\n",
    "\n",
    "  # step 4. calculate propagator dC/dA2 = dC/dZ3 * dZ3/dA2\n",
    "  dZ3_dA2 = W3 \n",
    "  dC_dA2 = W3.T @ dC_dZ3\n",
    "  assert dC_dA2.shape == (n[2], m)\n",
    "\n",
    "  return dC_dW3, dC_db3, dC_dA2\n",
    "\n",
    "\n",
    "def backprop_layer_2(propagator_dC_dA2, A1, A2, W2):\n",
    "\n",
    "  # step 1. calculate dC/dZ2 = dC/dA2 * dA2/dZ2\n",
    "\n",
    "  # use sigmoid derivation to arrive at this answer:\n",
    "  #   sigmoid'(z) = sigmoid(z) * (1 - sigmoid(z))\n",
    "  #     and if a = sigmoid(z), then sigmoid'(z) = a * (1 - a)\n",
    "  dA2_dZ2 = A2 * (1 - A2)\n",
    "  dC_dZ2 = propagator_dC_dA2 * dA2_dZ2\n",
    "  assert dC_dZ2.shape == (n[2], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW2 = dC/dZ2 * dZ2/dW2 \n",
    "  dZ2_dW2 = A1\n",
    "  assert dZ2_dW2.shape == (n[1], m)\n",
    "\n",
    "  dC_dW2 = dC_dZ2 @ dZ2_dW2.T\n",
    "  assert dC_dW2.shape == (n[2], n[1])\n",
    "\n",
    "  # step 3. calculate dC/db2 = np.sum(dC/dZ2, axis=1, keepdims=True)\n",
    "  dC_db2 = np.sum(dC_dW2, axis=1, keepdims=True)\n",
    "  assert dC_db2.shape == (n[2], 1)\n",
    "\n",
    "  # step 4. calculate propagator dC/dA1 = dC/dZ2 * dZ2/dA1\n",
    "  dZ2_dA1 = W2\n",
    "  dC_dA1 = W2.T @ dC_dZ2\n",
    "  assert dC_dA1.shape == (n[2], m)\n",
    "\n",
    "  return dC_dW2, dC_db2, dC_dA1\n",
    "\n",
    "def backprop_layer_1(propagator_dC_dA1, A1, A0, W1):\n",
    "\n",
    "  # step 1. calculate dC/dZ1 = dC/dA1 * dA1/dZ1\n",
    "\n",
    "  # use sigmoid derivation to arrive at this answer:\n",
    "  #   sigmoid'(z) = sigmoid(z) * (1 - sigmoid(z))\n",
    "  #     and if a = sigmoid(z), then sigmoid'(z) = a * (1 - a)\n",
    "  dA1_dZ1 = A1 * (1 - A1)\n",
    "  dC_dZ1 = propagator_dC_dA1 * dA1_dZ1\n",
    "  assert dC_dZ1.shape == (n[1], m)\n",
    "\n",
    "\n",
    "  # step 2. calculate dC/dW1 = dC/dZ1 * dZ1/dW1 \n",
    "  dZ1_dW1 = A0\n",
    "  assert dZ1_dW1.shape == (n[0], m)\n",
    "\n",
    "  dC_dW1 = dC_dZ1 @ dZ1_dW1.T\n",
    "  assert dC_dW1.shape == (n[1], n[0])\n",
    "\n",
    "  # step 3. calculate dC/db1 = np.sum(dC/dZ1, axis=1, keepdims=True)\n",
    "  dC_db1 = np.sum(dC_dW1, axis=1, keepdims=True)\n",
    "  assert dC_db1.shape == (n[1], 1)\n",
    "\n",
    "  return dC_dW1, dC_db1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cf017",
   "metadata": {},
   "source": [
    "y_hat, cache = feed_forward(A0)\n",
    "\n",
    "dC_dW3, dC_db3, dC_dA2 = backprop_layer_3(\n",
    "    y_hat, \n",
    "    Y, \n",
    "    m, \n",
    "    A2= cache[\"A2\"], \n",
    "    W3= W3\n",
    ")\n",
    "\n",
    "dC_dW2, dC_db2, dC_dA1 = backprop_layer_2(\n",
    "    propagator_dC_dA2=dC_dA2, \n",
    "    A1=cache[\"A1\"],\n",
    "    A2=cache[\"A2\"],\n",
    "    W2=W2\n",
    ")\n",
    "\n",
    "dC_dW1, dC_db1 = backprop_layer_1(\n",
    "    propagator_dC_dA1=dC_dA1, \n",
    "    A1=cache[\"A1\"],\n",
    "    A0=cache[\"A0\"],\n",
    "    W1=W1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18478c6",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6629794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  # must use global keyword in order to modify global variables\n",
    "  global W3, W2, W1, b3, b2, b1\n",
    "\n",
    "  epochs = 200 # training for 1000 iterations\n",
    "  alpha = 0.1 # set learning rate to 0.1\n",
    "  costs = [] # list to store costs\n",
    "\n",
    "  for e in range(epochs):\n",
    "    # 1. FEED FORWARD\n",
    "    y_hat, cache = feed_forward(A0)\n",
    "    \n",
    "    # 2. COST CALCULATION\n",
    "    error = cost(y_hat, Y)\n",
    "    costs.append(error)\n",
    "\n",
    "    # 3. BACKPROP CALCULATIONS\n",
    "\n",
    "    dC_dW3, dC_db3, dC_dA2 = backprop_layer_3(\n",
    "        y_hat, \n",
    "        Y, \n",
    "        m, \n",
    "        A2= cache[\"A2\"], \n",
    "        W3=W3\n",
    "    )\n",
    "\n",
    "    dC_dW2, dC_db2, dC_dA1 = backprop_layer_2(\n",
    "        propagator_dC_dA2=dC_dA2, \n",
    "        A1=cache[\"A1\"],\n",
    "        A2=cache[\"A2\"],\n",
    "        W2=W2\n",
    "    )\n",
    "\n",
    "    dC_dW1, dC_db1 = backprop_layer_1(\n",
    "        propagator_dC_dA1=dC_dA1, \n",
    "        A1=cache[\"A1\"],\n",
    "        A0=cache[\"A0\"],\n",
    "        W1=W1\n",
    "    )\n",
    "\n",
    "    # 4. UPDATE WEIGHTS\n",
    "    W3 = W3 - (alpha * dC_dW3)\n",
    "    W2 = W2 - (alpha * dC_dW2)\n",
    "    W1 = W1 - (alpha * dC_dW1)\n",
    "\n",
    "    b3 = b3 - (alpha * dC_db3)\n",
    "    b2 = b2 - (alpha * dC_db2)\n",
    "    b1 = b1 - (alpha * dC_db1)\n",
    "\n",
    "\n",
    "    if e % 20 == 0:\n",
    "      print(f\"epoch {e}: cost = {error:4f}\")\n",
    "  \n",
    "  return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a652bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost = 1.361685\n",
      "epoch 20: cost = 0.801696\n",
      "epoch 40: cost = 0.707331\n",
      "epoch 60: cost = 0.694909\n",
      "epoch 80: cost = 0.693365\n",
      "epoch 100: cost = 0.693174\n",
      "epoch 120: cost = 0.693151\n",
      "epoch 140: cost = 0.693148\n",
      "epoch 160: cost = 0.693147\n",
      "epoch 180: cost = 0.693147\n"
     ]
    }
   ],
   "source": [
    "costs = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
