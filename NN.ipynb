{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc3f599",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "48003d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446235ff",
   "metadata": {},
   "source": [
    "todo: initialise constants from the dataset (drop name column)\n",
    "todo: redefine feed forward generally\n",
    "todo: do todo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1bc6f",
   "metadata": {},
   "source": [
    "Intialise network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7ba24926",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3  # number of layers(excluding input layer)\n",
    "n = 2  # number of features\n",
    "m = 1  # number of output nodes\n",
    "\n",
    "hidden_layers = 3  # number of layers(excluding input layer)\n",
    "features = 2  # number of features\n",
    "outputs = 1  # number of output nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1e358a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(input_size=features, hidden_size=features+1, output_size=outputs, num_hidden_layers=hidden_layers):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    \n",
    "    alpha = 1  # scaling factor for weights\n",
    "    beta = 1   # scaling factor for biases\n",
    "\n",
    "    # Input to first hidden layer\n",
    "    weights.append(np.random.randn(hidden_size, input_size) * alpha)\n",
    "    biases.append(np.random.randn(hidden_size, 1) * beta)\n",
    "    \n",
    "    # Hidden layers\n",
    "    for i in range(num_hidden_layers - 1):\n",
    "        weights.append(np.random.randn(hidden_size, hidden_size) * alpha)\n",
    "        biases.append(np.random.randn(hidden_size, 1) * beta)\n",
    "    \n",
    "    # Last hidden to output layer\n",
    "    weights.append(np.random.randn(output_size, hidden_size) * alpha)\n",
    "    biases.append(np.random.randn(output_size, 1) * beta)\n",
    "    \n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "803fd336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights of the network: [array([[-0.67067813,  1.58424556],\n",
      "       [-1.56716802, -0.13680524],\n",
      "       [ 0.363363  , -1.34396603]]), array([[ 0.64717752,  0.09435585,  1.11632814],\n",
      "       [ 0.09918029, -0.26268643,  1.66045796],\n",
      "       [ 0.53110829,  0.71613359, -0.35120126]]), array([[-0.07381484,  0.76504959,  1.01929505],\n",
      "       [-1.23256697, -1.38050319,  1.55976749],\n",
      "       [ 0.41536909, -0.76064943, -0.91258583]]), array([[ 1.09904145, -0.50794855,  0.21683331]])]\n",
      "Biases of the network: [array([[ 0.92908401],\n",
      "       [ 0.11852676],\n",
      "       [-1.07764212]]), array([[-1.25924555],\n",
      "       [ 0.08180502],\n",
      "       [ 1.13123935]]), array([[ 0.44125189],\n",
      "       [-1.28014511],\n",
      "       [ 1.71620452]]), array([[2.40131438]])]\n"
     ]
    }
   ],
   "source": [
    "weights, biases = init_network()\n",
    "print(\"Weights of the network:\", weights)\n",
    "print(\"Biases of the network:\", biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c54697",
   "metadata": {},
   "source": [
    "Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b1ce2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "  X = np.array([\n",
    "      [150, 70],\n",
    "      [254, 73],\n",
    "      [312, 68],\n",
    "      [120, 60],\n",
    "      [154, 61],\n",
    "      [212, 65],\n",
    "      [216, 67],\n",
    "      [145, 67],\n",
    "      [184, 64],\n",
    "      [130, 69]\n",
    "  ])\n",
    "  y = np.array([0,1,1,0,0,1,1,0,1,0])\n",
    "  m = y.shape[0]  # number of samples\n",
    "  # Transpose the input matrix to match the expected shape\n",
    "  A0 = X.T\n",
    "  # Reshape y to a matrix\n",
    "  Y = y.reshape(outputs, m)\n",
    "\n",
    "  return A0, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa1882b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ed4b5",
   "metadata": {},
   "source": [
    "Activation function sigmoid \n",
    "$$g(z)=\\frac{1}{(1+e^{-z})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d161c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(arr):\n",
    "    return 1 / (1+np.exp(-1*arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c4b8e",
   "metadata": {},
   "source": [
    "Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fdd8be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(input_layer=x_train, num_hidden_layers=hidden_layers, weights=weights, biases=biases):\n",
    "  cache = [input_layer]\n",
    "  \n",
    "  for i in range(0,num_hidden_layers+1):\n",
    "    prev_layer = cache[i]\n",
    "    W = weights[i]\n",
    "    b = biases[i]\n",
    "    Z = W @ prev_layer + b\n",
    "    A = sigmoid(Z)\n",
    "    cache.append(A)\n",
    "\n",
    "  return cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "84444ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions of the network: [[0.96614655 0.96555063 0.96824829 0.96614656 0.96554848 0.96554679\n",
      "  0.96554676 0.96614653 0.96554674 0.96614656]]\n",
      "\n",
      "Predictions: [array([[150, 254, 312, 120, 154, 212, 216, 145, 184, 130],\n",
      "       [ 70,  73,  68,  60,  61,  65,  67,  67,  64,  69]]), array([[9.99986658e-001, 4.43181047e-024, 2.05433234e-044,\n",
      "        9.99999815e-001, 3.28084458e-003, 2.37555084e-017,\n",
      "        3.86131563e-017, 9.99945932e-001, 6.97181552e-010,\n",
      "        1.00000000e+000],\n",
      "       [6.31900549e-107, 6.89787712e-178, 4.57365844e-217,\n",
      "        6.50367817e-086, 4.10131284e-109, 7.93866207e-149,\n",
      "        1.14411611e-151, 2.40963983e-103, 1.03826669e-129,\n",
      "        2.96695497e-093],\n",
      "       [2.21603168e-018, 1.01387704e-003, 9.99999999e-001,\n",
      "        2.80640176e-017, 1.69783481e-012, 1.11676611e-005,\n",
      "        3.24965902e-006, 2.03036594e-017, 1.63328048e-009,\n",
      "        5.93091968e-021]]), array([[0.35158563, 0.22129877, 0.46433134, 0.35158757, 0.22146968,\n",
      "        0.22110594, 0.22110442, 0.35157962, 0.22110379, 0.3515876 ],\n",
      "       [0.5451229 , 0.52086002, 0.85097428, 0.54512322, 0.52052107,\n",
      "        0.52044449, 0.5204412 , 0.5451219 , 0.52043986, 0.54512322],\n",
      "       [0.84055195, 0.75600187, 0.68568832, 0.84055288, 0.75638877,\n",
      "        0.75606682, 0.75606733, 0.84054905, 0.75606754, 0.8405529 ]]), array([[0.84410789, 0.83117665, 0.8528252 , 0.84410803, 0.83119383,\n",
      "        0.83114333, 0.83114307, 0.84410746, 0.83114296, 0.84410803],\n",
      "       [0.23958133, 0.25109657, 0.12371369, 0.23958107, 0.25125846,\n",
      "        0.25126822, 0.25126958, 0.2395821 , 0.25127014, 0.23958107],\n",
      "       [0.66385455, 0.67305096, 0.65385568, 0.66385448, 0.67304562,\n",
      "        0.67308984, 0.67309015, 0.66385475, 0.67309027, 0.66385448]]), array([[0.96614655, 0.96555063, 0.96824829, 0.96614656, 0.96554848,\n",
      "        0.96554679, 0.96554676, 0.96614653, 0.96554674, 0.96614656]])]\n"
     ]
    }
   ],
   "source": [
    "cache = feed_forward(x_train)  # Get the output layer predictions\n",
    "predictions = cache[-1]  # Last layer output\n",
    "print(\"Predictions of the network:\", cache[-1])\n",
    "print(\"\\nPredictions:\", cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb48ba",
   "metadata": {},
   "source": [
    "Use loss as cost function: $L\\left(\\hat{y}_i y_i\\right)=-\\left(y_i \\ln \\hat{y}_i+\\left(1-y_i\\right) \\ln \\left(1-\\hat{y}_i\\right)\\right)$\n",
    "\n",
    "\n",
    "Hence cost given by: $C=\\frac{1}{m} \\sum_{i=1}^m L\\left(\\hat{y}_i, y_i\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "24f5db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y_hat=predictions, y=y_train):\n",
    "  \"\"\"\n",
    "  y_hat should be a n^L x m matrix\n",
    "  y should be a n^L x m matrix\n",
    "  \"\"\"\n",
    "\n",
    "  # Clip predictions to avoid log(0)\n",
    "  y_hat = np.clip(y_hat, 1e-15, 1 - 1e-15)\n",
    "\n",
    "  # 1. losses is a n^L x m\n",
    "  losses = - ( (y * np.log(y_hat)) + (1 - y)*np.log(1 - y_hat) )\n",
    "\n",
    "  return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "acb06e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.70835654655431\n"
     ]
    }
   ],
   "source": [
    "print(cost(predictions, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0125e8c",
   "metadata": {},
   "source": [
    "Backpropagation with formulas derived using calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8843ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_layer(dC_dA_current, A_current, A_prev, W_current, Y, layer_num):\n",
    "    \"\"\"\n",
    "    Backpropagation for a single layer.\n",
    "\n",
    "    Args:\n",
    "        dC_dA_current:  Propagator from the next layer (dC/dA[l+1]). For the output layer, this is None.\n",
    "        A_current:      Activations of the current layer (A[l])\n",
    "        A_prev:         Activations of the previous layer (A[l-1])\n",
    "        W_current:      Weights of the current layer (W[l])\n",
    "        Y:              True labels (only needed for the output layer)\n",
    "\n",
    "    Returns:\n",
    "        dC_dW: Gradient of cost with respect to weights\n",
    "        dC_db: Gradient of cost with respect to biases\n",
    "        dC_dA_prev: Propagator to the previous layer (dC/dA[l-1])\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate dC/dZ\n",
    "    if dC_dA_current is None:  # Output layer\n",
    "        dC_dZ = (1/m) * (A_current - Y)\n",
    "    else:  # Hidden layer\n",
    "        dA_dZ = A_current * (1 - A_current)\n",
    "        dC_dZ = dC_dA_current * dA_dZ\n",
    "\n",
    "\n",
    "    # calculate dC/dW\n",
    "    dZ_dW = A_prev\n",
    "    dC_dW = dC_dZ @ dZ_dW.T\n",
    "\n",
    "    # step 3. calculate dC/db\n",
    "    dC_db = np.sum(dC_dZ, axis=1, keepdims=True)\n",
    "\n",
    "    # calculate propagator to the prev layer\n",
    "    if layer_num != 0:  # Not the input layer\n",
    "        dZ_dA_prev = W_current\n",
    "        dC_dA_prev = W_current.T @ dC_dZ\n",
    "\n",
    "    else:\n",
    "        dC_dA_prev = None\n",
    "\n",
    "    return dC_dW, dC_db, dC_dA_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18478c6",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e6629794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=200, alpha=0.1, hidden_layers=hidden_layers, features=features, outputs=outputs):\n",
    "  global weights, biases, x_train, y_train\n",
    "  \n",
    "  costs = []\n",
    "  num_layers = hidden_layers + 1\n",
    "\n",
    "  for e in range(epochs):\n",
    "    # Feed forward\n",
    "    cache = feed_forward(x_train)\n",
    "    predictions = cache[-1]\n",
    "    \n",
    "    # Cost\n",
    "    costs.append(cost(predictions, y_train))\n",
    "\n",
    "    # Backpropagation \n",
    "    dC_dA_prev = None\n",
    "    updates = []\n",
    "    for layer_num in range(num_layers, 0, -1):\n",
    "        \n",
    "        A_current = cache[layer_num]\n",
    "        A_prev = cache[layer_num-1]\n",
    "        W_current = weights[layer_num-1]\n",
    "\n",
    "        dC_dW, dC_db, dC_dA_prev_new = backprop_layer(\n",
    "            dC_dA_current=dC_dA_prev, \n",
    "            A_current=A_current, \n",
    "            A_prev=A_prev, \n",
    "            W_current=W_current, \n",
    "            Y=y_train,\n",
    "            layer_num=layer_num\n",
    "        )\n",
    "        dC_dA_prev = dC_dA_prev_new\n",
    "        updates.insert(0, (dC_dW, dC_db))\n",
    "\n",
    "\n",
    "    # Update weights and biases\n",
    "    for layer_num in range(num_layers):\n",
    "        dC_dW, dC_db = updates[layer_num]\n",
    "\n",
    "        # Update weights and biases\n",
    "        weights[layer_num] -= alpha * dC_dW\n",
    "        biases[layer_num] -= alpha * dC_db\n",
    "\n",
    "\n",
    "    if e % 20 == 0:\n",
    "      print(f\"epoch {e}: cost = {costs[e]:4f}\")\n",
    "  \n",
    "  return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e85edc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,1,-1):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a652bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost = 1.708357\n",
      "epoch 20: cost = 0.689665\n",
      "epoch 40: cost = 0.675130\n",
      "epoch 60: cost = 0.615251\n",
      "epoch 80: cost = 0.415680\n",
      "epoch 100: cost = 0.211029\n",
      "epoch 120: cost = 0.122125\n",
      "epoch 140: cost = 0.082644\n",
      "epoch 160: cost = 0.061585\n",
      "epoch 180: cost = 0.048745\n"
     ]
    }
   ],
   "source": [
    "costs = train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
